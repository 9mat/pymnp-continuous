{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import theano.gradient\n",
    "import pyipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%env OMP_NUM_THREADS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../individual_data_wide.dta', 'rb') as fi:\n",
    "    df = pd.read_stata(fi)\n",
    "df = df[df.dv_rj==0]\n",
    "df.treattype = df.treattype.astype(int)\n",
    "df.choice = df.choice.astype(int)\n",
    "# df['treat1'] = df.treattype == 1\n",
    "# df['ntreat1'] = df.groupby(['date', 'stationid']).treat1.transform(sum)\n",
    "# df = df[df.ntreat1 > 0]\n",
    "choice = df.choice.as_matrix().astype(int)\n",
    "df.loc[choice==3, 'choice']=2\n",
    "df.loc[choice==2, 'choice']=3\n",
    "\n",
    "df['consumerid'] = df['consumerid'].astype(int)\n",
    "\n",
    "# df = df[df.choice < 4]\n",
    "# df = df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.choice.as_matrix().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(choice)\n",
    "print(df.choice.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_station, station_reverse_id = np.unique(df['stationid'].as_matrix(), return_inverse=True)\n",
    "nstation = len(unique_station)\n",
    "new_stationid = np.arange(nstation)\n",
    "df.stationid = new_stationid[station_reverse_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_dummies = pd.get_dummies(df['stationid'], prefix='dv_station')\n",
    "df[station_dummies.columns[1:]] = station_dummies[station_dummies.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dow_dummies = pd.get_dummies(df['date'].dt.dayofweek, prefix='dv_dow')\n",
    "df[dow_dummies.columns[1:]] = dow_dummies[dow_dummies.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputfile = './data_new_volume.csv'\n",
    "# df = pd.read_csv(inputfile)\n",
    "df.loc[:,'const'] = 1\n",
    "\n",
    "# df = df.sample(2000)\n",
    "\n",
    "df['pgmidgrade_km_adj'].fillna(value=10000, inplace=True)\n",
    "df['pemidgrade_km_adj'].fillna(value=10000, inplace=True)\n",
    "\n",
    "df = df.loc[df['treattype'] < 3]\n",
    "for elem in df['treattype'].unique():\n",
    "    df.loc[:,'treat' + str(elem)] = df['treattype'] == elem\n",
    "\n",
    "for elem in df['choice'].unique():\n",
    "    df.loc[:,'choice' + str(elem)] = df['choice'] == elem\n",
    "\n",
    "df.loc[:,'treat1_topusage'] = df['treat1']*df['dv_usageveh_p75p100']\n",
    "df.loc[:,'treat2_topusage'] = df['treat2']*df['dv_usageveh_p75p100']\n",
    "\n",
    "df.loc[:,'treat1_college'] = df['treat1']*df['dv_somecollege']\n",
    "df.loc[:,'treat2_college'] = df['treat2']*df['dv_somecollege']\n",
    "\n",
    "df.loc[:,'ltank'] = np.log(df['car_tank'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "plt.hist(df['choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price_labels = ['pg_km_adj', 'pe_km_adj', 'pgmidgrade_km_adj', 'pemidgrade_km_adj']\n",
    "# price_labels = ['pg_km_adj', 'pe_km_adj', 'pgmidgrade_km_adj']\n",
    "# price_labels = ['pg_km_adj', 'pe_km_adj']\n",
    "price_labels = price_labels[:max(df['choice'])]\n",
    "value_labels = ['value_total']\n",
    "\n",
    "# all\n",
    "# Xexpd_labels = ['dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'const'] #+ list(station_dummies.columns[1:])\n",
    "# Xutil_labels = ['dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'const'] #+ list(station_dummies.columns[1:])\n",
    "Xexpd_labels = ['ltank', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'dv_dow_1', 'dv_dow_2', 'dv_dow_3', 'dv_dow_4', 'dv_dow_5', 'dv_dow_6', 'dv_start_0901_1200',  'dv_start_1201_on', 'const'] #+ list(station_dummies.columns[1:])\n",
    "Xutil_labels = ['ltank', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'dv_dow_1', 'dv_dow_2', 'dv_dow_3', 'dv_dow_4', 'dv_dow_5', 'dv_dow_6', 'dv_start_0901_1200',  'dv_start_1201_on'] #+ list(station_dummies.columns[1:])\n",
    "\n",
    "# usage\n",
    "#Xexpd_labels = ['choice2', 'choice3', 'dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'stationvisit_avgcarprice_adj', 'const']\n",
    "#Xutil_labels = ['dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_carpriceadj_p75p100', 'stationvisit_avgcarprice_adj', 'const']\n",
    "\n",
    "# car price\n",
    "#Xexpd_labels = ['dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'const']\n",
    "#Xutil_labels = ['dv_ctb', 'dv_bh', 'dv_rec', 'dv_female', 'dv_age_25to40y', 'dv_age_morethan65y', 'dv_somesecondary', 'dv_somecollege', 'dv_usageveh_p75p100', 'stationvisit_avgcarprice_adj', 'const']\n",
    "\n",
    "Xlelas_labels = ['const', 'treat1', 'treat2']\n",
    "# Xlelas_labels = ['const', 'treat1', 'treat2', 'treat3', 'treat4']\n",
    "# Xlelas_labels = ['const', 'treat1', 'treat2', 'dv_usageveh_p75p100', 'treat1_topusage', 'treat2_topusage']\n",
    "# Xlelas_labels = ['const', 'treat1', 'treat2', 'dv_somecollege', 'treat1_college', 'treat2_college']\n",
    "# Xlelas_labels = ['const', 'treat1', 'treat2', 'dv_usageveh_p75p100', 'dv_somecollege', 'treat1_topusage', 'treat2_topusage', 'treat1_college', 'treat2_college']\n",
    "Xlsigma_labels = ['const']\n",
    "Xlmu_labels = ['const']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_count_choice = df[['stationid','choice', 'const']].groupby(['stationid','choice']).sum()\n",
    "idf_fe = theano.shared(1-np.isnan(df_count_choice.unstack().as_matrix()).astype(floatX), 'idf_fe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "choice = theano.shared(df.loc[:, 'choice'].as_matrix() - 1, 'choice', 'int32')\n",
    "price  = theano.shared(df.loc[:, price_labels].as_matrix().astype(floatX), 'price')\n",
    "value  = theano.shared(df.loc[:, value_labels].as_matrix().astype(floatX), 'value', broadcastable=(False, True))\n",
    "Xexpd  = theano.shared(df.loc[:, Xexpd_labels].as_matrix().astype(floatX), 'Xexpd')\n",
    "Xutil  = theano.shared(df.loc[:, Xutil_labels].as_matrix().astype(floatX), 'Xutil')\n",
    "stationid  = theano.shared(df.loc[:, 'stationid'].as_matrix(), 'station', 'int32')\n",
    "\n",
    "Xlelas = theano.shared(df.loc[:, Xlelas_labels].as_matrix().astype(floatX), 'Xlelas')\n",
    "Xlmu   = theano.shared(df.loc[:, Xlmu_labels].as_matrix().astype(floatX), 'Xlmu')\n",
    "Xlsigma = theano.shared(df.loc[:, Xlsigma_labels].as_matrix().astype(floatX), 'Xlsigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _, stationid = T.extra_ops.Unique(False, True, False)(station)\n",
    "# nstation = stationid.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nobs = len(df)\n",
    "nchoice = len(price_labels)\n",
    "nXexpd = len(Xexpd_labels)\n",
    "nXutil = len(Xutil_labels)\n",
    "\n",
    "nXlelas = len(Xlelas_labels)\n",
    "nXlsigma = len(Xlsigma_labels)\n",
    "nXlmu = len(Xlmu_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvchoice = T.eq(choice.reshape((-1,1)), np.arange(nchoice, dtype=int).reshape((1,-1)))\n",
    "chosenprice = T.sum(price*dvchoice,axis=1,keepdims=True)\n",
    "convenience_expend = 50.0\n",
    "dvconvenience = T.abs_(value.squeeze()-convenience_expend) < 1e-3\n",
    "n_convenience = dvconvenience.sum()\n",
    "convenience = dvconvenience.nonzero()\n",
    "inconvenience = (~dvconvenience).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utilfe = True\n",
    "expdfe = False\n",
    "\n",
    "nstation1 = nstation\n",
    "ntheta = (nXlelas + nXlsigma + nXlmu + nXexpd + \n",
    "          (nchoice-1)*nXutil + \n",
    "          (nstation1-1 if expdfe else 0) + \n",
    "          ((nchoice-1)*(nstation1) if utilfe else 0))\n",
    "\n",
    "theta0 = np.zeros(ntheta)\n",
    "theta0[0] = 0.1\n",
    "theta00 = np.hstack([theta0, [0.1]])\n",
    "theta000 = np.hstack([theta00, [0.]*(nchoice-1)]) # alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getparams(theta, expdfe=False, utilfe=False):\n",
    "    offset = 0\n",
    "    gammalelas = theta[offset:offset+nXlelas].reshape((nXlelas, 1))\n",
    "    \n",
    "    offset += nXlelas\n",
    "    gammalsigma = theta[offset:offset+nXlsigma].reshape((nXlsigma, 1))\n",
    "    \n",
    "    offset += nXlsigma\n",
    "    gammalmu = theta[offset:offset+nXlmu].reshape((nXlmu, 1))\n",
    "    \n",
    "    offset += nXlmu\n",
    "    betaexpd = theta[offset:offset+nXexpd].reshape((nXexpd, 1))\n",
    "    \n",
    "    offset += nXexpd\n",
    "    betautil = theta[offset:offset+(nchoice-1)*nXutil].reshape((nXutil, nchoice-1))\n",
    "        \n",
    "    offset += (nchoice-1)*nXutil\n",
    "    ltpconve = theta[offset]\n",
    "    \n",
    "    offset += 1\n",
    "    alphaexpend = theta[offset:offset+nchoice-1]\n",
    "    \n",
    "    offset += nchoice-1\n",
    "\n",
    "    betaexpdfe = None\n",
    "    if expdfe:\n",
    "        betaexpdfe = theta[offset:offset+(nstation-1)].reshape((-1,1))\n",
    "        offset += (nstation-1)\n",
    "\n",
    "    betautilfe = None\n",
    "    if utilfe:\n",
    "        betautilfe = theta[offset:offset+(nchoice-1)*(nstation)].reshape((-1,nchoice-1))\n",
    "        offset += (nstation-1)*(nstation)\n",
    "    \n",
    "    return gammalelas, gammalsigma, gammalmu, betaexpd, betautil, ltpconve, alphaexpend, betaexpdfe, betautilfe\n",
    "\n",
    "theta = T.dvector('theta')\n",
    "\n",
    "gammalelas, gammalsigma, gammalmu, betaexpd, betautil, ltpconve, alphaexpend, betaexpdfe, betautilfe = getparams(theta, expdfe, utilfe)\n",
    "\n",
    "pconve = T.nnet.sigmoid(ltpconve)\n",
    "\n",
    "if utilfe:\n",
    "    betautilfe = T.concatenate([T.zeros((nstation,1)), betautilfe], axis=1) - 1e9*(1-idf_fe)\n",
    "#     betautilfe = T.concatenate([T.zeros((nstation,1)), betautilfe], axis=1)\n",
    "#     betautilfe = T.concatenate([T.zeros((1,nchoice)), betautilfe], axis=0)\n",
    "    \n",
    "if expdfe:\n",
    "    betaexpdfe = T.concatenate([[[0]], betaexpdfe], axis=0)\n",
    "    \n",
    "alphaexpend = T.concatenate([T.zeros(1,), alphaexpend],axis=0)\n",
    "\n",
    "def logsumexp(x,axis,w=idf_fe):\n",
    "    maxx = T.max(x,axis=axis,keepdims=True)\n",
    "    return maxx.squeeze() + T.log(T.sum(T.exp(x-maxx)*(w[stationid] if w is not None else 1.0),axis=axis))\n",
    "#     return maxx.squeeze() + T.log(T.sum(T.exp(x-maxx),axis=axis))\n",
    "\n",
    "def logsumexp2(x,y):\n",
    "    m = T.maximum(x,y)\n",
    "    return m + T.log(T.exp(x-m) + T.exp(y-m))\n",
    "\n",
    "dvchoicef = dvchoice.astype(floatX)\n",
    "\n",
    "mu = T.exp(T.dot(Xlmu, gammalmu))\n",
    "elas = T.exp(T.dot(Xlelas, gammalelas))\n",
    "lsigma = T.dot(Xlsigma,gammalsigma)\n",
    "rho = elas - 1\n",
    "elasdrho = elas/rho\n",
    "\n",
    "lconvenience_expend = np.log(convenience_expend)\n",
    "\n",
    "alphachoice = alphaexpend[choice].dimshuffle([0,'x'])\n",
    "\n",
    "eta = T.log(value) + rho*T.log(chosenprice) - T.dot(Xexpd,betaexpd) - alphachoice - (betaexpdfe[stationid,:] if expdfe else 0)\n",
    "lexpend = T.log(value) - rho*(T.log(price) - T.log(chosenprice)) + alphaexpend - alphachoice\n",
    "\n",
    "utilhete = T.concatenate([T.zeros((Xutil.shape[0],1)), T.dot(Xutil, betautil)],axis=1) + (betautilfe[stationid,:] if utilfe else 0) \n",
    "utilquant = T.exp(lexpend)/rho\n",
    "\n",
    "util0 = (utilquant + utilhete)/mu\n",
    "lprobchoice0 = T.sum(util0*dvchoice,axis=1) - logsumexp(util0,1)\n",
    "\n",
    "lprobchoice = lprobchoice0 + np.log(1-pconve)\n",
    "lpdfeta = eta*eta/(2*T.exp(2*lsigma)) + lsigma + np.log(2*np.pi)/2\n",
    "ll1 = -lprobchoice + lpdfeta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://pomax.github.io/bezierinfo/legendre-gauss.html\n",
    "weight = np.array([0.2491470458, 0.2491470458, 0.2334925365, 0.2334925365, \n",
    "                   0.2031674267, 0.2031674267, 0.1600783285, 0.1600783285, \n",
    "                   0.106939326, 0.106939326, 0.0471753364, 0.0471753364]).reshape(1,-1)\n",
    "abscissa = np.array([-0.1252334085, 0.1252334085, -0.367831499, 0.367831499, \n",
    "                     -0.5873179543, 0.5873179543, -0.7699026742, 0.7699026742, \n",
    "                     -0.9041172564, 0.9041172564, -0.9815606342, 0.9815606342]).reshape(1,-1)\n",
    "\n",
    "# Hermite Gaussian quadrature\n",
    "# http://keisan.casio.com/exec/system/1329114617\n",
    "abscissa = np.array([-3.88972489786978000, -3.02063702512089000, -2.27950708050106000, -1.59768263515260000, \n",
    "                   -0.94778839124016300, -0.31424037625435900, 0.31424037625435900, 0.94778839124016300, \n",
    "                   1.59768263515260000, 2.27950708050106000, 3.02063702512089000, 3.88972489786978000\n",
    "                  ]).reshape(-1,1,1)\n",
    "\n",
    "weight = np.array([0.00000026585516844, 0.00008573687043588, 0.00390539058462906, 0.05160798561588390, \n",
    "                     0.26049231026416100, 0.57013523626248000, 0.57013523626248000, 0.26049231026416100, \n",
    "                     0.05160798561588390, 0.00390539058462906, 0.00008573687043588, 0.00000026585516844\n",
    "                     ]).reshape(-1,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss - Hermite quadrature\n",
    "$$\\int_{-\\infty}^{\\infty} e^{-x^2}f(x)dx \\approx \\sum w_i f(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eta_i = T.exp(lsigma)*abscissa\n",
    "lexpend_i = lexpend - eta + eta_i\n",
    "utilconve_i = (T.exp((lexpend_i-lconvenience_expend)/elas)/(1-1/elas) - 1)*convenience_expend\n",
    "utilb = (utilconve_i + utilhete)/mu\n",
    "lprobchoice_i = T.sum(utilconve_i*dvchoicef,axis=2) - logsumexp(utilconve_i,2)\n",
    "ll = lprobchoice_i + np.log(weight)[:,:,0] - np.log(2*np.pi)/2\n",
    "ll2 = -logsumexp(ll,0,None) - T.log(pconve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlogl_total = ll1[inconvenience].sum() + logsumexp2(ll1, ll2)[convenience].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildfunc(theta, nloglf):\n",
    "    return (theano.function([theta], nloglf),\n",
    "            theano.function([theta], T.grad(nloglf, theta)),\n",
    "            theano.function([theta], theano.gradient.hessian(nloglf, theta)))\n",
    "\n",
    "eval_f, eval_grad, eval_hess = buildfunc(theta, nlogl_total)\n",
    "# eval_f = theano.function([theta], nlogl_total)\n",
    "# eval_grad = theano.function([theta], T.grad(nlogl_total, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.function([theta],ll2)(theta000).shape\n",
    "# abscissa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyipopt.set_loglevel(1)\n",
    "thetahat , _, _, _, _, fval = pyipopt.fmin_unconstrained(\n",
    "    eval_f,\n",
    "    theta000,\n",
    "    fprime=eval_grad,\n",
    "    fhess=eval_hess,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_row1(lbl, hat, se, t): \n",
    "    formatstr = '%30s%10.3f%10.3f%10.3f'\n",
    "    print formatstr % (lbl, hat, se, t) \n",
    "\n",
    "def print_row2(lbl, hat, se, t):\n",
    "    star = np.sum(np.abs(t) > [1.65, 1.96, 2.58]) \n",
    "    print '{:>30}{:10.3f}{:<3}'.format(lbl, float(hat), '*'*star) \n",
    "    print '{:>40}]'.format('[{:.3f}'.format(float(se))) \n",
    "    \n",
    "def print_row3(lbl, hat, se, t): \n",
    "    star = np.sum(np.abs(t) > [1.65, 1.96, 2.58]) \n",
    "    print '{},=\"{:.3f}\",{}'.format(lbl, float(hat), '*'*star) \n",
    "    print ',=\"[{:.3f}]\"'.format(float(se))\n",
    "    \n",
    "def print_results(thetahat, print_row=print_row2):\n",
    "    covhat = np.linalg.pinv(eval_hess(thetahat))\n",
    "    sehat = np.sqrt(np.diagonal(covhat))\n",
    "    t = thetahat/sehat\n",
    "\n",
    "    gammalelashat, gammalsigmahat, gammalmuhat, betaexpdhat, betautilhat, bhat, alphahat,_,_ = getparams(thetahat)\n",
    "    gammalelasse, gammalsigmase, gammalmuse, betaexpdse, betautilse, bse, alphase, _, _ = getparams(sehat)\n",
    "    gammalelast, gammalsigmat, gammalmut, betaexpdt, betautilt, bt, alphat, _, _ = getparams(t)\n",
    "\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** ln(elas) equation'\n",
    "    for i in range(nXlelas):\n",
    "        print_row(Xlelas_labels[i], gammalelashat[i], gammalelasse[i], gammalelast[i])\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** ln(sigma) equation'\n",
    "    for i in range(nXlsigma):\n",
    "        print_row(Xlsigma_labels[i], gammalsigmahat[i], gammalsigmase[i], gammalsigmat[i])\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** ln(mu) equation'\n",
    "    for i in range(nXlmu):\n",
    "        print_row(Xlmu_labels[i], gammalmuhat[i], gammalmuse[i], gammalmut[i])\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** Expenditure equation'\n",
    "    for i in range(nchoice-1):\n",
    "        print_row('alpha_' + str(i), alphahat[i], alphase[i], alphat[i])\n",
    "\n",
    "    for i in range(nXexpd):\n",
    "        print_row(Xexpd_labels[i], betaexpdhat[i], betaexpdse[i], betaexpdt[i])\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** Discrete choice equation'\n",
    "    for j in range(nchoice-1):\n",
    "        print '-------- choice', j+1, '------------------------------------------'\n",
    "        for i in range(nXutil):\n",
    "            print_row(Xutil_labels[i], betautilhat[i][j], betautilse[i][j], betautilt[i][j])\n",
    "    print '-'*60\n",
    "\n",
    "    print ' \\n*** logit prob convenience'\n",
    "    print_row('const', bhat, bse, bt) \n",
    "    print '-'*60\n",
    "    \n",
    "    dtreat = gammalelas[1,0] - gammalelas[2,0]\n",
    "    grad_dtreat = T.grad(dtreat, theta)\n",
    "    grad_value = theano.function([theta], grad_dtreat)(thetahat)\n",
    "    se_dtreat = np.sqrt(grad_value.dot(covhat).dot(grad_value))\n",
    "    dtreat_hat = theano.function([theta], dtreat)(thetahat)\n",
    "    print dtreat_hat\n",
    "    print se_dtreat\n",
    "    \n",
    "print_results(thetahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_sample_by_station(df, resampled_stationid, nstation=nstation):\n",
    "    assert(len(df['stationid'].unique()) == nstation)\n",
    "    assert(df['stationid'].min()==0)\n",
    "    assert(df['stationid'].max()==nstation-1)\n",
    "    \n",
    "    resampled_df = pd.DataFrame()\n",
    "    for i in range(len(resampled_stationid)):\n",
    "        df2 = df[df['stationid']==resampled_stationid[i]].copy()\n",
    "        df2['stationid'] = i\n",
    "        resampled_df = resampled_df.append(df2)\n",
    "        \n",
    "    return resampled_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resampled_stationid = resample(np.arange(nstation),replace=True,n_samples=nstation)\n",
    "dfbstr = bootstrap_sample_by_station(df,resampled_stationid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return gammalelas, gammalsigma, gammalmu, betaexpd, betautil, ltpconve, alphaexpend, betaexpdfe, betautilfe\n",
    "gammalelashat, gammalsigmahat, gammalmuhat, betaexpdhat, betautilhat, ltpconvehat, alphahat, betaexpdfehat, betautilfehat = getparams(thetahat, expdfe, utilfe)\n",
    "\n",
    "if utilfe:\n",
    "    newbetautilfehat = betautilfehat[resampled_stationid]\n",
    "\n",
    "if expdfe:\n",
    "    newbetaexpdfehat = np.concatenate([[[0]], betaexpdfehat], axis=0) + betaexpdhat[-1] #betaexpdhat[-1] is const\n",
    "    newbetaexpdfehat = newbetaexpdfehat[resampled_stationid]\n",
    "    betaexpdhat[-1] = newbetaexpdfehat[0]\n",
    "    newbetaexpdfehat = newbetaexpdfehat - betaexpdhat[-1]\n",
    "\n",
    "newthetahat = np.hstack([a.ravel() for a in (gammalelashat, gammalsigmahat, gammalmuhat, betaexpdhat, betautilhat, \n",
    "                                             ltpconvehat, alphahat, \n",
    "                                             newbetaexpdfehat[1:] if expdfe else np.zeros([]), \n",
    "                                             newbetautilfehat if utilfe else np.zeros([]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_shared_value(df):\n",
    "    choice.set_value(df.loc[:, 'choice'].as_matrix().astype(np.int64) - 1)\n",
    "    price.set_value(df.loc[:, price_labels].as_matrix().astype(floatX))\n",
    "    value.set_value(df.loc[:, value_labels].as_matrix().astype(floatX))\n",
    "    Xexpd.set_value(df.loc[:, Xexpd_labels].as_matrix().astype(floatX))\n",
    "    Xutil.set_value(df.loc[:, Xutil_labels].as_matrix().astype(floatX))\n",
    "    stationid.set_value(df.loc[:, 'stationid'].as_matrix().astype(np.int64))\n",
    "\n",
    "    df_count_choice = df[['stationid','choice', 'const']].groupby(['stationid','choice']).sum()\n",
    "    idf_fe.set_value(1-np.isnan(df_count_choice.unstack().as_matrix()).astype(floatX))\n",
    "    \n",
    "    Xlelas.set_value(df.loc[:, Xlelas_labels].as_matrix().astype(floatX))\n",
    "    Xlmu.set_value(df.loc[:, Xlmu_labels].as_matrix().astype(floatX))\n",
    "    Xlsigma.set_value(df.loc[:, Xlsigma_labels].as_matrix().astype(floatX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gammalelashat, gammalsigmahat, gammalmuhat, betaexpdhat, betautilhat, ltpconvehat, alphahat, betaexpdfehat, betautilfehat = getparams(thetahat, expdfe, utilfe)\n",
    "\n",
    "def bootstrap(df, randskip, nbstr):\n",
    "    np.random.seed(1234)\n",
    "    for i in range(randskip):\n",
    "        resampled_stationid = resample(np.arange(nstation),replace=True,n_samples=nstation)\n",
    "        \n",
    "    bstrres = []\n",
    "    for i in range(randskip, randskip+nbstr):\n",
    "        resampled_stationid = resample(np.arange(nstation),replace=True,n_samples=nstation)\n",
    "        dfbstr = bootstrap_sample_by_station(df,resampled_stationid)        \n",
    "        if utilfe:\n",
    "            newbetautilfehat = betautilfehat[resampled_stationid]\n",
    "\n",
    "        if expdfe:\n",
    "            newbetaexpdfehat = np.concatenate([[[0]], betaexpdfehat], axis=0) + betaexpdhat[-1] #betaexpdhat[-1] is const\n",
    "            newbetaexpdfehat = newbetaexpdfehat[resampled_stationid]\n",
    "            betaexpdhat[-1] = newbetaexpdfehat[0]\n",
    "            newbetaexpdfehat = newbetaexpdfehat - betaexpdhat[-1]\n",
    "\n",
    "        newthetahat = np.hstack([a.ravel() for a in (gammalelashat, gammalsigmahat, gammalmuhat, betaexpdhat, betautilhat, \n",
    "                                                     ltpconvehat, alphahat, \n",
    "                                                     newbetaexpdfehat[1:] if expdfe else np.zeros([]), \n",
    "                                                     newbetautilfehat if utilfe else np.zeros([]))])\n",
    "        \n",
    "        set_shared_value(dfbstr)\n",
    "        thetahat2 , _, _, _, nloglvalue, status = pyipopt.fmin_unconstrained(\n",
    "            eval_f,\n",
    "            newthetahat,\n",
    "            fprime=eval_grad,\n",
    "            fhess=eval_hess,)\n",
    "        \n",
    "        bstrres.append([i, thetahat2, nloglvalue, status, eval_grad(thetahat2)])\n",
    "        \n",
    "    return bstrres\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bstrres = bootstrap(df,25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_results(bstrres[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set_shared_value(dfbstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print_results(bstrres[1][1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
